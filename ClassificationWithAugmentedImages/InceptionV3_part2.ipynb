{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from keras import backend as K \n",
    "import gc \n",
    "from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
    "from keras import layers \n",
    "from keras.optimizers import Adam \n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "import itertools\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard \n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from keras.engine.topology import get_source_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((464, 150, 150, 3), (464,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"x_train_200_no_val.npy\")\n",
    "y_train = np.load(\"y_train_200_no_val.npy\")\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116, 150, 150, 3), (116,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev = np.load(\"x_test_200_no_val.npy\")\n",
    "y_dev = np.load(\"y_test_200_no_val.npy\")\n",
    "x_dev.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.models import Sequential , Model \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "# # create the base pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model \n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "  \n",
    "model = Model( base_model.input, x) \n",
    "  \n",
    "model.compile(optimizer = RMSprop(lr=0.0001),loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "232/232 - 187s - loss: 60.0400 - acc: 0.5668 - val_loss: 19.0722 - val_acc: 0.5776\n",
      "Epoch 2/20\n",
      "232/232 - 223s - loss: 24.4740 - acc: 0.6185 - val_loss: 29.0174 - val_acc: 0.5345\n",
      "Epoch 3/20\n",
      "232/232 - 98s - loss: 19.1378 - acc: 0.6056 - val_loss: 20.1312 - val_acc: 0.5603\n",
      "Epoch 4/20\n",
      "232/232 - 106s - loss: 9.6778 - acc: 0.6789 - val_loss: 7.2839 - val_acc: 0.6121\n",
      "Epoch 5/20\n",
      "232/232 - 95s - loss: 4.4897 - acc: 0.6228 - val_loss: 3.5965 - val_acc: 0.6810\n",
      "Epoch 6/20\n",
      "232/232 - 92s - loss: 2.1781 - acc: 0.6918 - val_loss: 1.2557 - val_acc: 0.6638\n",
      "Epoch 7/20\n",
      "232/232 - 92s - loss: 1.7175 - acc: 0.6466 - val_loss: 2.0771 - val_acc: 0.5690\n",
      "Epoch 8/20\n",
      "232/232 - 89s - loss: 1.1793 - acc: 0.6595 - val_loss: 1.0657 - val_acc: 0.6897\n",
      "Epoch 9/20\n",
      "232/232 - 88s - loss: 1.2036 - acc: 0.6595 - val_loss: 0.6124 - val_acc: 0.6810\n",
      "Epoch 10/20\n",
      "232/232 - 88s - loss: 0.9380 - acc: 0.7155 - val_loss: 1.3378 - val_acc: 0.7069\n",
      "Epoch 11/20\n",
      "232/232 - 89s - loss: 1.4116 - acc: 0.6681 - val_loss: 0.7378 - val_acc: 0.6810\n",
      "Epoch 12/20\n",
      "232/232 - 88s - loss: 0.9975 - acc: 0.6940 - val_loss: 2.2406 - val_acc: 0.6121\n",
      "Epoch 13/20\n",
      "232/232 - 89s - loss: 1.3228 - acc: 0.6875 - val_loss: 1.3404 - val_acc: 0.6466\n",
      "Epoch 14/20\n",
      "232/232 - 89s - loss: 0.8851 - acc: 0.6961 - val_loss: 0.7074 - val_acc: 0.6724\n",
      "Epoch 15/20\n",
      "232/232 - 89s - loss: 0.9198 - acc: 0.7328 - val_loss: 1.0945 - val_acc: 0.7414\n",
      "Epoch 16/20\n",
      "232/232 - 88s - loss: 0.9566 - acc: 0.7392 - val_loss: 1.0081 - val_acc: 0.6897\n",
      "Epoch 17/20\n",
      "232/232 - 88s - loss: 0.8423 - acc: 0.7155 - val_loss: 0.8084 - val_acc: 0.7414\n",
      "Epoch 18/20\n",
      "232/232 - 88s - loss: 0.8234 - acc: 0.7220 - val_loss: 1.4975 - val_acc: 0.7069\n",
      "Epoch 19/20\n",
      "232/232 - 89s - loss: 0.7941 - acc: 0.7716 - val_loss: 1.0627 - val_acc: 0.7069\n",
      "Epoch 20/20\n",
      "232/232 - 88s - loss: 0.6751 - acc: 0.7414 - val_loss: 1.7017 - val_acc: 0.6379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ddc554bcd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data = (x_dev,y_dev), epochs=20, batch_size=2,  verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
